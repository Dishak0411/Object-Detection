{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"V28","mount_file_id":"1WJWJicK8O9xdwLPSitf9xa4FFqu-obV7","authorship_tag":"ABX9TyOf2C3CyZQGxIB8QFSJTYhl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"TPU"},"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8WiaPujdf8l3","executionInfo":{"status":"ok","timestamp":1726502010932,"user_tz":-330,"elapsed":4399,"user":{"displayName":"Disha Khandelwal","userId":"06470109862090070073"}},"outputId":"0da34f47-b016-4eb9-96f2-c47131c3ae19"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.9/41.9 kB\u001b[0m \u001b[31m718.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m872.7/872.7 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]}],"source":["!pip install ultralytics --quiet"]},{"cell_type":"code","source":["from ultralytics import YOLO\n","import os\n","from IPython.display import display, Image\n","from IPython import display\n","display.clear_output()"],"metadata":{"id":"zaRQU7tcgX1m","executionInfo":{"status":"ok","timestamp":1726502028981,"user_tz":-330,"elapsed":10243,"user":{"displayName":"Disha Khandelwal","userId":"06470109862090070073"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["!pip install roboflow --quiet\n","\n","from roboflow import Roboflow\n","rf = Roboflow(api_key=\"zJ3fUc7lArRAzgMQxBjt\")\n","project = rf.workspace(\"final-year-workspace\").project(\"final1-dja1f\")\n","version = project.version(1)\n","dataset = version.download(\"yolov8\")\n",""],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gtFK9vHugEhK","executionInfo":{"status":"ok","timestamp":1726502074975,"user_tz":-330,"elapsed":10048,"user":{"displayName":"Disha Khandelwal","userId":"06470109862090070073"}},"outputId":"9c91e465-5caa-4d20-eb2e-d35d3cce1a23"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/80.3 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━\u001b[0m \u001b[32m61.4/80.3 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.3/80.3 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m66.8/66.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.9/49.9 MB\u001b[0m \u001b[31m23.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.5/54.5 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","loading Roboflow workspace...\n","loading Roboflow project...\n","Dependency ultralytics==8.0.196 is required but found version=8.2.94, to fix: `pip install ultralytics==8.0.196`\n"]},{"output_type":"stream","name":"stderr","text":["Downloading Dataset Version Zip in Final1-1 to yolov8:: 100%|██████████| 115306/115306 [00:01<00:00, 69214.56it/s]"]},{"output_type":"stream","name":"stdout","text":["\n"]},{"output_type":"stream","name":"stderr","text":["\n","Extracting Dataset Version Zip to Final1-1 in yolov8:: 100%|██████████| 5212/5212 [00:00<00:00, 7275.63it/s]\n"]}]},{"cell_type":"code","source":["!yolo task = detect mode = train model = yolov8n.pt data = \"/content/Final1-1/data.yaml\" epochs = 20 imgsz = 640"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"s_sWIDcNgaze","executionInfo":{"status":"ok","timestamp":1726506745455,"user_tz":-330,"elapsed":2733272,"user":{"displayName":"Disha Khandelwal","userId":"06470109862090070073"}},"outputId":"19982660-ba91-4e07-ae6f-ce0f15ccf108"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n","100% 6.25M/6.25M [00:00<00:00, 80.9MB/s]\n","Ultralytics YOLOv8.2.94 🚀 Python-3.10.12 torch-2.4.0+cpu CPU (Intel Xeon 2.00GHz)\n","\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=/content/Final1-1/data.yaml, epochs=20, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/detect/train\n","Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n","100% 755k/755k [00:00<00:00, 14.7MB/s]\n","Overriding model.yaml nc=80 with nc=4\n","\n","                   from  n    params  module                                       arguments                     \n","  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n","  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n","  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n","  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n","  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n","  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n","  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n","  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n","  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n","  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n"," 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n"," 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n"," 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n"," 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n"," 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n"," 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n"," 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n"," 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n"," 22        [15, 18, 21]  1    752092  ultralytics.nn.modules.head.Detect           [4, [64, 128, 256]]           \n","Model summary: 225 layers, 3,011,628 parameters, 3,011,612 gradients, 8.2 GFLOPs\n","\n","Transferred 319/355 items from pretrained weights\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/detect/train', view at http://localhost:6006/\n","Freezing layer 'model.22.dfl.conv.weight'\n","\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/Final1-1/train/labels... 2078 images, 0 backgrounds, 0 corrupt: 100% 2078/2078 [00:01<00:00, 1326.78it/s]\n","\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/Final1-1/train/labels.cache\n","WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 88, len(boxes) = 5120. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","\u001b[34m\u001b[1mval: \u001b[0mScanning /content/Final1-1/valid/labels... 246 images, 0 backgrounds, 0 corrupt: 100% 246/246 [00:00<00:00, 1240.71it/s]\n","\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/Final1-1/valid/labels.cache\n","WARNING ⚠️ Box and segment counts should be equal, but got len(segments) = 11, len(boxes) = 487. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n","Plotting labels to runs/detect/train/labels.jpg... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n","\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.00125, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n","\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added ✅\n","Image sizes 640 train, 640 val\n","Using 0 dataloader workers\n","Logging results to \u001b[1mruns/detect/train\u001b[0m\n","Starting training for 20 epochs...\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       1/20         0G      1.279      2.162      1.439         64        640: 100% 130/130 [03:31<00:00,  1.63s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:11<00:00,  1.42s/it]\n","                   all        246        487      0.659      0.532      0.628       0.39\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       2/20         0G      1.273      1.553      1.411         56        640: 100% 130/130 [03:37<00:00,  1.67s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:11<00:00,  1.38s/it]\n","                   all        246        487      0.707      0.663      0.713      0.428\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       3/20         0G       1.27      1.446      1.413         40        640: 100% 130/130 [03:38<00:00,  1.68s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:11<00:00,  1.40s/it]\n","                   all        246        487      0.593      0.685       0.66      0.374\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       4/20         0G      1.273      1.409      1.423         60        640: 100% 130/130 [03:36<00:00,  1.66s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:11<00:00,  1.41s/it]\n","                   all        246        487      0.652      0.728      0.714      0.451\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       5/20         0G      1.235      1.272      1.389         47        640: 100% 130/130 [03:34<00:00,  1.65s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.35s/it]\n","                   all        246        487      0.619      0.748      0.718      0.442\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       6/20         0G      1.185      1.173      1.355         64        640: 100% 130/130 [03:35<00:00,  1.66s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.35s/it]\n","                   all        246        487      0.709      0.741      0.745      0.507\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       7/20         0G      1.175       1.14       1.35         50        640: 100% 130/130 [03:37<00:00,  1.68s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.27s/it]\n","                   all        246        487      0.702       0.77      0.772       0.53\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       8/20         0G      1.143      1.071      1.329         65        640: 100% 130/130 [03:40<00:00,  1.70s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:11<00:00,  1.49s/it]\n","                   all        246        487      0.748      0.802      0.783      0.537\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","       9/20         0G      1.119       1.04      1.317         38        640: 100% 130/130 [03:40<00:00,  1.70s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:11<00:00,  1.39s/it]\n","                   all        246        487      0.773      0.798      0.798       0.54\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      10/20         0G      1.092      1.007        1.3         75        640: 100% 130/130 [03:37<00:00,  1.68s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.28s/it]\n","                   all        246        487      0.714      0.782      0.811      0.556\n","Closing dataloader mosaic\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      11/20         0G      1.075     0.9736      1.321         45        640: 100% 130/130 [03:32<00:00,  1.63s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.31s/it]\n","                   all        246        487      0.683      0.807      0.811      0.572\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      12/20         0G      1.061     0.9111       1.31         40        640: 100% 130/130 [03:33<00:00,  1.64s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.26s/it]\n","                   all        246        487       0.74      0.843      0.827      0.581\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      13/20         0G      1.028     0.8836      1.299         33        640: 100% 130/130 [03:35<00:00,  1.66s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.27s/it]\n","                   all        246        487      0.754      0.801       0.82      0.577\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      14/20         0G      1.011     0.8503      1.275         55        640: 100% 130/130 [03:36<00:00,  1.67s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.29s/it]\n","                   all        246        487      0.706      0.869      0.825      0.577\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      15/20         0G     0.9848      0.822      1.258         33        640: 100% 130/130 [03:33<00:00,  1.64s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:09<00:00,  1.24s/it]\n","                   all        246        487      0.688      0.858      0.832      0.596\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      16/20         0G     0.9694     0.7912      1.242         40        640: 100% 130/130 [03:34<00:00,  1.65s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.29s/it]\n","                   all        246        487      0.758      0.818      0.847      0.608\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      17/20         0G     0.9484     0.7685      1.231         37        640: 100% 130/130 [03:33<00:00,  1.64s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.27s/it]\n","                   all        246        487      0.729      0.845       0.83      0.605\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      18/20         0G     0.9341     0.7403       1.23         41        640: 100% 130/130 [03:35<00:00,  1.66s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.29s/it]\n","                   all        246        487      0.753      0.859      0.843      0.607\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      19/20         0G     0.9268     0.7172      1.217         34        640: 100% 130/130 [03:33<00:00,  1.64s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:10<00:00,  1.34s/it]\n","                   all        246        487      0.728      0.858      0.845      0.615\n","\n","      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n","      20/20         0G     0.9026     0.7143      1.205         38        640: 100% 130/130 [03:35<00:00,  1.66s/it]\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:09<00:00,  1.24s/it]\n","                   all        246        487      0.708      0.874      0.842       0.62\n","\n","20 epochs completed in 1.262 hours.\n","Optimizer stripped from runs/detect/train/weights/last.pt, 6.2MB\n","Optimizer stripped from runs/detect/train/weights/best.pt, 6.2MB\n","\n","Validating runs/detect/train/weights/best.pt...\n","Ultralytics YOLOv8.2.94 🚀 Python-3.10.12 torch-2.4.0+cpu CPU (Intel Xeon 2.00GHz)\n","Model summary (fused): 168 layers, 3,006,428 parameters, 0 gradients, 8.1 GFLOPs\n","                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100% 8/8 [00:08<00:00,  1.08s/it]\n","                   all        246        487      0.708      0.874      0.842      0.619\n","                  Boot         50         98      0.787      0.929       0.91      0.666\n","                   Cap        179        223      0.643      0.964        0.9      0.689\n","                 Glove         53         97      0.472      0.639      0.596       0.25\n","                Person         66         69       0.93      0.963       0.96      0.872\n","Speed: 0.9ms preprocess, 27.4ms inference, 0.0ms loss, 0.3ms postprocess per image\n","Results saved to \u001b[1mruns/detect/train\u001b[0m\n","💡 Learn more at https://docs.ultralytics.com/modes/train\n"]}]}]}